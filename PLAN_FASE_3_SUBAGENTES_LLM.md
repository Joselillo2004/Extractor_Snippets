# üöÄ PLAN FASE 3: SUBAGENTES LLM PARA AN√ÅLISIS CONTEXTUAL

## üìã RESUMEN EJECUTIVO

**Proyecto**: Extractor de Snippets Python  
**Fase**: 3 - Enriquecimiento con Inteligencia Artificial  
**Objetivo**: Elevar success rate de 37.4% a 85%+ mediante subagentes LLM especializados  
**Estado Actual**: Fase 2 completada exitosamente  
**Target**: Resolver 113 runtime errors restantes mediante an√°lisis contextual inteligente

---

## üéØ SITUACI√ìN ACTUAL (POST-FASE 2)

### ‚úÖ **Logros Conseguidos**
- **185 snippets exitosos** de 495 total (37.4% success rate)
- **95% reducci√≥n** en errores sint√°cticos (257 ‚Üí 13)
- **Sistema de normalizaci√≥n** robusto implementado
- **Pipeline estable** con parser + validador + sandbox

### üéØ **Problemas Pendientes**
- **113 runtime errors** por contexto faltante
  - `NameError: name 'var1' is not defined`
  - `NameError: name 'Student' is not defined`  
  - `ModuleNotFoundError: No module named 'xyz'`
- **Dependencias complejas** entre snippets distantes
- **Contexto distribuido** a lo largo del archivo de referencia

---

## üß† CONCEPTO: SUBAGENTES LLM ESPECIALIZADOS

### **Problema Central**
Las heur√≠sticas simples no pueden capturar dependencias sem√°nticas complejas entre snippets que est√°n separados por decenas o cientos de l√≠neas en el archivo fuente.

### **Soluci√≥n Propuesta**
Arquitectura de **subagentes LLM especializados** que trabajen en conjunto para:
1. **Analizar contexto** de snippets aleda√±os
2. **Validar coherencia** sem√°ntica  
3. **Construir contexto** espec√≠fico y optimizado

---

## ü§ñ ARQUITECTURA DE SUBAGENTES

### **1. Context Analyzer Agent**
```python
Responsabilidad: An√°lisis de contexto distributivo
Input: Snippet actual + ventana de snippets (¬±N posiciones)
Output: Mapa de dependencias (variables, clases, imports, funciones)

Casos de uso:
- Detectar variable 'lista' definida en snippet #45 para uso en #47
- Encontrar clase 'Student' definida en snippet #125 para #127
- Identificar imports establecidos en snippets anteriores
```

### **2. Validity Agent** 
```python
Responsabilidad: Diagn√≥stico de validez inteligente
Input: Snippet + an√°lisis de contexto
Output: Diagn√≥stico detallado + confianza + recomendaciones

Capacidades:
- Determinar si snippet necesita contexto adicional
- Evaluar completitud de dependencias
- Clasificar tipos de problemas detectados
```

### **3. Context Builder Agent**
```python
Responsabilidad: Construcci√≥n de contexto optimizado
Input: Diagn√≥stico + contexto disponible
Output: C√≥digo de contexto m√≠nimo y funcional

Optimizaciones:
- Contexto m√≠nimo necesario (no redundante)
- Valores realistas para variables
- Imports solo cuando realmente se usan
```

---

## üí° CASOS DE USO ESPEC√çFICOS

### **Ejemplo 1: Variable Definida Anteriormente**
```python
# Snippet #45: lista = [1, 2, 3, 4, 5]
# ...intervalo de snippets...
# Snippet #47: print(lista[0])  # ‚Üê FALLA: NameError: 'lista' not defined

Context Analyzer ‚Üí Escanea ¬±20 snippets, encuentra 'lista' en #45
Validity Agent ‚Üí Confirma que necesita contexto de lista
Context Builder ‚Üí Genera: lista = [1, 2, 3, 4, 5]
Resultado ‚Üí Snippet ejecuta exitosamente
```

### **Ejemplo 2: Clase Definida Previamente**
```python
# Snippet #125: class Student:
#                   def __init__(self, name): self.name = name
# ...intervalo...  
# Snippet #127: student = Student("Juan")  # ‚Üê FALLA: NameError: 'Student'

Context Analyzer ‚Üí Encuentra definici√≥n completa de Student en #125
Context Builder ‚Üí Incluye clase completa con m√©todos
Resultado ‚Üí Instanciaci√≥n exitosa
```

### **Ejemplo 3: Cadena de Dependencias**
```python
# Snippet #200: import random
# Snippet #201: def roll_dice(): return random.randint(1,6)
# Snippet #203: result = roll_dice()  # ‚Üê FALLA: m√∫ltiples dependencias

Context Analyzer ‚Üí Detecta cadena import ‚Üí funci√≥n ‚Üí uso
Context Builder ‚Üí Construye contexto completo con import + funci√≥n
Resultado ‚Üí Ejecuci√≥n completa exitosa
```

---

## üèóÔ∏è IMPLEMENTACI√ìN T√âCNICA

### **Estructura de M√≥dulos**
```
src/snippets/agents/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ base_agent.py          # Clase base abstracta
‚îú‚îÄ‚îÄ context_analyzer.py    # Context Analyzer Agent
‚îú‚îÄ‚îÄ validity_agent.py      # Validity Agent  
‚îú‚îÄ‚îÄ context_builder.py     # Context Builder Agent
‚îú‚îÄ‚îÄ llm_client.py         # Cliente Groq configurado
‚îî‚îÄ‚îÄ prompt_templates/      # Templates de prompts
    ‚îú‚îÄ‚îÄ context_analysis.txt
    ‚îú‚îÄ‚îÄ validity_check.txt
    ‚îî‚îÄ‚îÄ context_building.txt
```

### **Pipeline de Procesamiento**
```python
def enhanced_validate(snippet, all_snippets, snippet_index, use_agents=True):
    # Fase 1: Validaci√≥n heur√≠stica (existente)
    basic_result = validate(snippet, normalize=True)
    
    if basic_result.status == 'ok' or not use_agents:
        return basic_result
    
    # Fase 2: An√°lisis LLM (solo si falla heur√≠stica)
    try:
        # Paso 1: An√°lisis contextual
        context_info = context_analyzer.analyze(
            snippet, all_snippets, snippet_index, window_size=20
        )
        
        # Paso 2: Validaci√≥n inteligente
        validity_result = validity_agent.assess(snippet, context_info)
        
        # Paso 3: Construcci√≥n de contexto
        if validity_result.needs_context:
            enhanced_context = context_builder.build(snippet, context_info)
            enhanced_snippet = enhanced_context + "\n\n" + snippet
            
            # Paso 4: Validaci√≥n final
            return validate(enhanced_snippet, normalize=True)
    
    except Exception as e:
        # Fallback graceful a resultado heur√≠stico
        logging.warning(f"LLM agent failed: {e}")
        return basic_result
    
    return basic_result
```

---

## üìä DEPENDENCIAS Y VALIDACI√ìN

### **Dependencias Principales**
```python
# Validadas con brave_web_search
groq==0.4.1          # Cliente oficial Groq (VERIFICADO: seguro, no slopsquatting)
pydantic>=2.0.0      # Validaci√≥n de esquemas de respuesta  
tenacity>=8.0.0      # Retry logic para API calls
```

### **Dependencias de Desarrollo**
```python
pytest-asyncio      # Tests async para agentes
pytest-mock         # Mocking de API calls
aioresponses        # Mock HTTP responses
```

---

## üéõÔ∏è CONFIGURACI√ìN Y CONTROL

### **Par√°metros CLI Nuevos**
```bash
--use-agents          # Habilitar subagentes LLM (default: False)
--agent-model         # Modelo LLM (default: llama-3.1-70b-versatile)
--context-window      # Ventana de an√°lisis (default: 20 snippets)
--agent-cache         # Cache de resultados LLM (default: True)
--max-agent-cost      # L√≠mite de costo por ejecuci√≥n (default: $5.00)
```

### **Variables de Entorno**
```bash
GROQ_API_KEY         # API key de Groq (requerida)
AGENT_LOG_LEVEL      # Nivel de logging (default: INFO)
AGENT_CACHE_DIR      # Directorio de cache (default: .agent_cache/)
```

---

## üí∞ AN√ÅLISIS DE COSTOS Y PERFORMANCE

### **Estimaci√≥n de Costos**
```python
Snippets objetivo: 113 (solo runtime errors)
Tokens promedio por snippet: ~500 tokens
Costo por 1K tokens (Groq): ~$0.0002
Costo estimado por ejecuci√≥n completa: $2-5
Costo por snippet rescatado: ~$0.02-0.04
```

### **Optimizaciones de Costo**
- **Procesamiento selectivo**: Solo snippets fallidos
- **Cache inteligente**: Evitar re-an√°lisis de contextos similares
- **Rate limiting**: Control de requests por minuto
- **Early termination**: Parar si confianza es baja

### **M√©tricas Target**
```python
Success Rate Actual: 37.4% (185/495)
Success Rate Target: 85%+ (420+/495)
Runtime Errors: 113 ‚Üí ~20 esperado
Snippets rescatados esperados: ~235
Tiempo adicional por snippet: ~2-3 segundos
```

---

## üß™ ESTRATEGIA DE TESTING (TDD)

### **Tests por M√≥dulo**
```python
tests/agents/
‚îú‚îÄ‚îÄ test_base_agent.py           # Tests para clase base
‚îú‚îÄ‚îÄ test_context_analyzer.py     # Tests an√°lisis contextual
‚îú‚îÄ‚îÄ test_validity_agent.py       # Tests validaci√≥n inteligente  
‚îú‚îÄ‚îÄ test_context_builder.py      # Tests construcci√≥n contexto
‚îú‚îÄ‚îÄ test_llm_client.py          # Tests cliente Groq
‚îî‚îÄ‚îÄ test_integration.py         # Tests integraci√≥n completa
```

### **Mocks y Fixtures**
```python
@pytest.fixture
def mock_groq_client():
    """Mock del cliente Groq para tests"""
    
@pytest.fixture  
def sample_snippets():
    """Conjunto de snippets de prueba con dependencias conocidas"""

@pytest.fixture
def expected_contexts():
    """Contextos esperados para validaci√≥n"""
```

---

## üîÑ PLAN DE IMPLEMENTACI√ìN

### **Fase 3.1: Preparaci√≥n (TDD + Base)**
- [ ] Setup de entorno con dependencias validadas
- [ ] Implementaci√≥n de `base_agent.py` con TDD
- [ ] Cliente LLM (`llm_client.py`) con manejo de errores robusto
- [ ] Tests de integraci√≥n b√°sica con Groq API

### **Fase 3.2: Context Analyzer Agent**
- [ ] Implementaci√≥n TDD de an√°lisis contextual
- [ ] Prompts optimizados para detecci√≥n de dependencias
- [ ] Ventana din√°mica de an√°lisis
- [ ] Cache de an√°lisis contextual

### **Fase 3.3: Validity + Context Builder Agents**
- [ ] Validity Agent con diagn√≥stico detallado
- [ ] Context Builder con generaci√≥n optimizada
- [ ] Integraci√≥n de los 3 agentes en pipeline
- [ ] Tests de casos complejos

### **Fase 3.4: Integraci√≥n y Optimizaci√≥n**
- [ ] Integraci√≥n con CLI existente
- [ ] Optimizaci√≥n de performance y costos
- [ ] Logging detallado y m√©tricas
- [ ] Documentaci√≥n completa

### **Fase 3.5: Validaci√≥n Final**
- [ ] Ejecuci√≥n completa sobre archivo de referencia
- [ ] An√°lisis de mejoras vs Fase 2
- [ ] Reporte final con m√©tricas detalladas
- [ ] Actualizaci√≥n de documentaci√≥n

---

## üéØ CRITERIOS DE √âXITO

### **M√©tricas Quantitativas**
- **Success Rate**: 37.4% ‚Üí 85%+ 
- **Runtime Errors**: 113 ‚Üí ‚â§20
- **Costo por snippet rescatado**: ‚â§$0.05
- **Tiempo adicional**: ‚â§5 segundos promedio por snippet

### **M√©tricas Cualitativas**
- **Robustez**: Sistema funciona sin agentes (fallback)
- **Usabilidad**: CLI intuitivo, configuraci√≥n simple
- **Mantenibilidad**: C√≥digo TDD, logging completo
- **Escalabilidad**: Funciona con otros archivos de referencia

---

## üö® CONSIDERACIONES DE RIESGO

### **Riesgos T√©cnicos**
- **API Rate Limits**: Mitigado con rate limiting + cache
- **Costo excesivo**: Mitigado con l√≠mites configurables
- **Latencia alta**: Mitigado con procesamiento as√≠ncrono
- **Calidad de respuestas LLM**: Mitigado con validaci√≥n + fallback

### **Riesgos de Implementaci√≥n**
- **Complejidad alta**: Mitigado con TDD riguroso
- **Debugging dif√≠cil**: Mitigado con logging detallado
- **Dependencia externa**: Mitigado con fallback a heur√≠sticas

---

## üìà ROADMAP POST-FASE 3

### **Extensiones Potenciales**
- **Multi-modelo**: Soporte para otros LLMs (OpenAI, Claude)
- **Especializaci√≥n**: Agentes espec√≠ficos por tipo de snippet
- **Aprendizaje**: Cache inteligente que mejora con uso
- **Exportadores**: Integraci√≥n con IDE, notebooks, documentaci√≥n

### **Escalabilidad**
- **Otros lenguajes**: Extensi√≥n a Java, C++, etc.
- **Otros formatos**: Libros t√©cnicos, tutoriales, documentaci√≥n
- **Colaborativo**: Sharing de contextos entre usuarios

---

## üéØ CONCLUSI√ìN

La **Fase 3 con Subagentes LLM** representa un salto cualitativo en el proyecto:

- **Inteligencia sem√°ntica** vs heur√≠sticas simples
- **Escalabilidad natural** a otros tipos de archivos
- **ROI claro**: ~$2-5 de costo por ~235 snippets rescatados
- **Arquitectura robusta** con fallbacks y TDD completo

**El plan es t√©cnicamente s√≥lido, financieramente viable y estrat√©gicamente coherente.**

---

*Documentado por: Asistente IA*  
*Fecha: 7 de Agosto, 2025*  
*Estado: Plan aprobado para implementaci√≥n*
