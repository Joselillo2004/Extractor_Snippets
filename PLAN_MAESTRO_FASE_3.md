# ğŸš€ PLAN MAESTRO FASE 3: IMPLEMENTACIÃ“N SUBAGENTES LLM

## ğŸ“‹ ESTADO ACTUAL Y OBJETIVO

**Proyecto**: Extractor de Snippets Python  
**Fase Actual**: TransiciÃ³n de Fase 2 a Fase 3  
**Success Rate Actual**: 37.4% (185/495 snippets)  
**Success Rate Objetivo**: 85%+ (420+/495 snippets)  
**Problema Principal**: 113 runtime errors por contexto faltante

---

## ğŸ› ï¸ PROTOCOLO OBLIGATORIO

1. âœ… **`sequentialthinking`** para planificaciÃ³n estratÃ©gica
2. ğŸ **Activar entorno virtual** existente (protocolo venv)
3. ğŸ” **Validar dependencias** con `brave_web_search` (anti-slopsquatting)
4. ğŸ§ª **TDD con pytest** (tests primero, implementaciÃ³n despuÃ©s)
5. ğŸ§  **Actualizar memoria** tras cada hito importante
6. ğŸ“‹ **Generar reporte markdown** final con mÃ©tricas
7. ğŸ“¢ **ComunicaciÃ³n clara** durante todo el proceso

---

## ğŸ“Š PLAN DETALLADO (12 PASOS CRÃTICOS)

### ğŸ” FASE A: DIAGNÃ“STICO Y PREPARACIÃ“N (Pasos 1-3)

#### Paso 1: ValidaciÃ³n Entorno Virtual
- [ ] âœ… Detectar proyecto Python por `requirements.txt` o `*.py`
- [ ] ğŸ” Verificar existencia de `venv/` en raÃ­z del proyecto
- [ ] âš¡ Validar integridad del entorno (python.exe, pip, estructura completa)
- [ ] ğŸ› Si corrupto: AVISAR problema y CONFIRMAR eliminaciÃ³n antes de recrear
- [ ] ğŸ¯ ActivaciÃ³n con validaciÃ³n doble: `$VIRTUAL_ENV` Y prompt `(venv)`
- [ ] ğŸ“ **Criterio Ã©xito**: Entorno activo y funcional al 100%

#### Paso 2: RevisiÃ³n DocumentaciÃ³n TÃ©cnica
- [ ] ğŸ“š Revisar `PLAN_FASE_3_SUBAGENTES_LLM.md` completo
- [ ] ğŸ¯ Validar que arquitectura de 3 subagentes estÃ¡ clara
- [ ] ğŸ“Š Confirmar mÃ©tricas objetivo: 37.4% â†’ 85% success rate
- [ ] ğŸ’° Revisar lÃ­mites de costo: $2-5 por ejecuciÃ³n completa
- [ ] ğŸ“ **Criterio Ã©xito**: Plan tÃ©cnico 100% comprendido

#### Paso 3: ValidaciÃ³n Dependencias Anti-Slopsquatting
- [ ] ğŸ” Ejecutar `brave_web_search` para validar `groq==0.4.1`
- [ ] ğŸ›¡ï¸ Verificar que es paquete oficial (no slopsquatting)
- [ ] ğŸ“¦ Validar dependencias secundarias: `pydantic>=2.0.0`, `tenacity>=8.0.0`
- [ ] ğŸ§ª Instalar dependencias de desarrollo: `pytest-asyncio`, `pytest-mock`
- [ ] ğŸ“ **Criterio Ã©xito**: Todas las dependencias validadas como seguras

### ğŸš€ FASE B: IMPLEMENTACIÃ“N GRADUAL TDD (Pasos 4-9)

#### Paso 4: Context Analyzer - Tests + ImplementaciÃ³n
- [ ] ğŸ§ª **TDD**: Crear `tests/agents/test_context_analyzer.py` PRIMERO
- [ ] ğŸ“‹ Tests casos especÃ­ficos:
  - DetecciÃ³n variable definida Â±N snippets
  - DetecciÃ³n clase definida previamente
  - IdentificaciÃ³n cadena de imports
  - Manejo ventana dinÃ¡mica (Â±20 snippets)
- [ ] ğŸ”¨ **ImplementaciÃ³n**: `src/snippets/agents/context_analyzer.py`
- [ ] âš¡ IntegraciÃ³n con cliente LLM (`llm_client.py`)
- [ ] ğŸ“Š Tests de performance: tiempo < 3 segundos por anÃ¡lisis
- [ ] ğŸ“ **Criterio Ã©xito**: 100% tests passing + anÃ¡lisis contextual funcional

#### Paso 5: Context Analyzer - IntegraciÃ³n
- [ ] ğŸ”„ Integrar con pipeline actual de validaciÃ³n
- [ ] ğŸ›ï¸ Feature flag: `enable_context_analyzer=True/False`
- [ ] ğŸ“Š Tests de integraciÃ³n con dataset pequeÃ±o (10 snippets)
- [ ] ğŸ› Debugging y logs detallados
- [ ] ğŸ“ **Criterio Ã©xito**: Context Analyzer integrado sin regresiones

#### Paso 6: Context Builder - Tests + ImplementaciÃ³n
- [ ] ğŸ§ª **TDD**: Crear `tests/agents/test_context_builder.py` PRIMERO
- [ ] ğŸ“‹ Tests casos especÃ­ficos:
  - ConstrucciÃ³n contexto mÃ­nimo para variables
  - ConstrucciÃ³n contexto completo para clases
  - OptimizaciÃ³n: evitar cÃ³digo redundante
  - GeneraciÃ³n valores realistas
- [ ] ğŸ”¨ **ImplementaciÃ³n**: `src/snippets/agents/context_builder.py`
- [ ] ğŸ¯ IntegraciÃ³n con resultados de Context Analyzer
- [ ] ğŸ“ **Criterio Ã©xito**: 100% tests passing + construcciÃ³n contextual funcional

#### Paso 7: Context Builder - IntegraciÃ³n
- [ ] ğŸ”„ Integrar Context Analyzer â†’ Context Builder pipeline
- [ ] ğŸ“Š Tests de casos complejos: cadenas de dependencias
- [ ] ğŸ’° Monitoreo de costos: tracking tokens por snippet
- [ ] ğŸ“ **Criterio Ã©xito**: Pipeline Aâ†’B funcional con mÃ©tricas claras

#### Paso 8: Validity Agent - Tests + ImplementaciÃ³n
- [ ] ğŸ§ª **TDD**: Crear `tests/agents/test_validity_agent.py` PRIMERO
- [ ] ğŸ“‹ Tests casos especÃ­ficos:
  - DiagnÃ³stico necesidad de contexto
  - EvaluaciÃ³n completitud dependencias
  - ClasificaciÃ³n tipos de problemas
  - Scoring de confianza
- [ ] ğŸ”¨ **ImplementaciÃ³n**: `src/snippets/agents/validity_agent.py`
- [ ] ğŸ¯ ValidaciÃ³n final del contexto construido
- [ ] ğŸ“ **Criterio Ã©xito**: 100% tests passing + validaciÃ³n inteligente funcional

#### Paso 9: Validity Agent - IntegraciÃ³n Completa
- [ ] ğŸ”„ Integrar pipeline completo: Context Analyzer â†’ Context Builder â†’ Validity Agent
- [ ] ğŸ›ï¸ Feature flag maestro: `enable_llm_subagents=True/False`
- [ ] ğŸ›¡ï¸ Fallback automÃ¡tico a Fase 2 si algÃºn agente falla
- [ ] ğŸ“ **Criterio Ã©xito**: Los 3 subagentes funcionando en armonÃ­a

### âœ… FASE C: INTEGRACIÃ“N Y VALIDACIÃ“N (Pasos 10-12)

#### Paso 10: Tests de IntegraciÃ³n Completos
- [ ] ğŸ§ª Tests de integraciÃ³n con casos reales del dataset
- [ ] ğŸ¯ ValidaciÃ³n de los 113 runtime errors objetivo
- [ ] ğŸ›¡ï¸ Tests de fallback cuando LLM falla
- [ ] ğŸ“Š Tests de performance: tiempo total < +50% vs Fase 2
- [ ] ğŸ’° Tests de costo: mantenerse dentro de $2-5
- [ ] ğŸ“ **Criterio Ã©xito**: Sistema robusto bajo todas las condiciones

#### Paso 11: EjecuciÃ³n Dataset Completo con MÃ©tricas
- [ ] ğŸ¯ Ejecutar sobre los 495 snippets completos
- [ ] ğŸ“Š MÃ©tricas crÃ­ticas:
  - Success rate actual vs 85% objetivo
  - Runtime errors: 113 â†’ â‰¤20 esperado
  - Tiempo procesamiento total
  - Costo real vs estimado
  - Snippets rescatados por cada agente
- [ ] ğŸ“‹ Comparativa detallada vs Fase 2 (37.4% baseline)
- [ ] ğŸ“ **Criterio Ã©xito**: Objetivos cumplidos o plan de ajuste definido

#### Paso 12: Reporte Final y ActualizaciÃ³n Memoria
- [ ] ğŸ“‹ Generar reporte markdown con:
  - MÃ©tricas antes/despuÃ©s detalladas
  - AnÃ¡lisis de costos reales
  - Casos edge detectados
  - Recomendaciones optimizaciÃ³n
  - Lecciones aprendidas
- [ ] ğŸ§  Actualizar memoria con resultados especÃ­ficos
- [ ] ğŸ“š Actualizar documentaciÃ³n tÃ©cnica
- [ ] ğŸ‰ Plan maestro completado exitosamente
- [ ] ğŸ“ **Criterio Ã©xito**: DocumentaciÃ³n completa y memoria actualizada

---

## ğŸ¯ MÃ‰TRICAS DE Ã‰XITO POR FASE

### Fase A (PreparaciÃ³n):
- âœ… Entorno virtual 100% funcional
- âœ… Dependencias 100% validadas como seguras
- âœ… Plan tÃ©cnico 100% comprendido

### Fase B (ImplementaciÃ³n):
- âœ… 100% tests coverage en nuevos componentes
- âœ… Context Analyzer: detecciÃ³n dependencias >90%
- âœ… Context Builder: construcciÃ³n contexto optimizado
- âœ… Validity Agent: diagnÃ³stico inteligente funcional
- âœ… Pipeline integrado sin regresiones

### Fase C (ValidaciÃ³n):
- ğŸ¯ **Success rate: 37.4% â†’ 85%**
- ğŸ¯ **Runtime errors: 113 â†’ â‰¤20**
- ğŸ¯ **Tiempo: +50% mÃ¡ximo vs Fase 2**
- ğŸ¯ **Costo: $2-5 por dataset completo**
- ğŸ¯ **Robustez: 100% snippets procesables (con/sin LLM)**

---

## ğŸ›¡ï¸ ESTRATEGIA DE ROLLBACK Y MITIGACIÃ“N

- **Feature flags** granulares por cada subagente
- **Fallback automÃ¡tico** a Fase 2 (37.4% garantizado)
- **Tests de regresiÃ³n** continuos
- **Logging diferenciado** para debugging rÃ¡pido
- **Cache de resultados** para minimizar re-procesamiento
- **Rate limiting** para evitar lÃ­mites de API
- **Timeouts configurables** para evitar bloqueos

---

## ğŸ“Š DIAGRAMA DE FLUJO DEL PROCESO

```
INPUT: snippet â†’ [normalizer.py] â†’ [validador.py]
  |
  â”œâ”€â”€ SUCCESS (37.4%) â†’ âœ… Resultado ok (mantener)
  |
  â””â”€â”€ ERROR (62.6%) â†’ [FASE 3: LLM Subagentes]
      |
      â”œâ”€â”€ 1. Context Analyzer: Analiza dependencias
      |     |
      â”œâ”€â”€ 2. Validity Agent: EvalÃºa necesidad contexto
      |     |
      â”œâ”€â”€ 3. Context Builder: Construye contexto mÃ­nimo
      |     |
      â””â”€â”€ OUTPUT: snippet mejorado â†’ [validador.py]
          |
          â”œâ”€â”€ SUCCESS â†’ âœ… Resultado ok (+47.6% esperado)
          |
          â””â”€â”€ ERROR â†’ âŒ Fallo (â‰¤15% esperado)
```

---

## ğŸš¨ LOGGING PARA DEBUGGING

### Niveles de Logging Implementados
- **DEBUG**: Detalles internos de procesamiento (prompts, responses)
- **INFO**: Flujo normal, decisiones, mÃ©tricas
- **WARNING**: Problemas no crÃ­ticos, fallbacks
- **ERROR**: Fallos recuperables, retries
- **CRITICAL**: Fallos irrecuperables

### Formato y RotaciÃ³n
- **Formato**: `[TIMESTAMP] [LEVEL] [AGENT] [SNIPPET_ID] - Message`
- **RotaciÃ³n**: Logs diarios con compresiÃ³n
- **UbicaciÃ³n**: `/logs/agents/YYYY-MM-DD.log`

---

*Documentado por: Asistente IA*  
*Fecha: 8 de Agosto, 2025*  
*VersiÃ³n: 1.0*
